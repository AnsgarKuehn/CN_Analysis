{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddda619-b7da-4eed-a1b1-e1cd2a7df350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import trange\n",
    "import re\n",
    "from lmfit.models import GaussianModel, StepModel, Model\n",
    "from cn_tools.cns_fit import cns_pc_from_file\n",
    "from cn_tools.cns_fit import cns_cut\n",
    "from cn_tools.cns_fit import mu_from_gauss\n",
    "from cn_tools.cns_fit import sigma_from_cns\n",
    "from cn_tools.cns_fit import Z_from_cns\n",
    "from cn_tools.cns_fit import compute_local_contacts\n",
    "from cn_tools.cns_fit import compute_nearest_neighbours\n",
    "from cn_tools.cns_fit import compute_mean_sigma\n",
    "from cn_tools.cns_fit import approximate_diameter\n",
    "from cn_tools.data_processing import prepare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22d22f3-018b-4a86-8bb2-9636d5f7f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['../Data/preprocessed/VF_005_analysis/', '../Data/preprocessed/VF_006_analysis/',\n",
    "               '../Data/preprocessed/VF_007_analysis/', '../Data/preprocessed/VF_008_analysis/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a3b7a5-ecd6-442f-ba22-25f6a4966d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mu(directory, upper_range = 2, namespace = ''):\n",
    "    '''Iterates through a raw directory and saves all processed csv files in another directory called preprocessed'''\n",
    "    \n",
    "    #define save directory\n",
    "    save_file = f'../Data/preprocessed{namespace}/mu.csv'\n",
    "    if not os.path.isdir(f'../Data/preprocessed{namespace}'):\n",
    "        os.mkdir(f'../Data/preprocessed{namespace}')\n",
    "    if os.path.isfile(save_file):\n",
    "        df_mu = pd.read_csv(save_file, index_col=0)\n",
    "    else: \n",
    "        df_mu = pd.DataFrame()\n",
    "        \n",
    "    #create list of all minkowski file folders to evaluate\n",
    "    files = [directory + file for file in os.listdir(directory) if 'tomo' in file]\n",
    "    \n",
    "    #for folder in folders:\n",
    "    for i in trange(len(files)):\n",
    "        file_name = files[i]\n",
    "        index = file_name[-11:-4] #index has the form 'XXX_YYY'\n",
    "        interval, cns, pc = cns_pc_from_file(file_name, upper_range = upper_range)\n",
    "        mu = mu_from_gauss(interval, pc)\n",
    "        df_mu.loc[index, 'mu'] = mu\n",
    "        \n",
    "    df_mu.to_csv(save_file)\n",
    "    \n",
    "def compute_sigmas(directory, upper_range = 2, namespace = ''):\n",
    "    '''Iterates through a raw directory and saves all processed csv files in another directory called preprocessed'''\n",
    "        \n",
    "    #define save directory\n",
    "    save_file = f'../Data/preprocessed{namespace}/sigma.csv'\n",
    "    if os.path.isfile(save_file):\n",
    "        df_sigma = pd.read_csv(save_file, index_col=0)\n",
    "    else: \n",
    "        df_sigma = pd.DataFrame()\n",
    "    \n",
    "    final_dir = re.sub('preprocessed', 'final', directory)\n",
    "    if not os.path.isdir(final_dir):\n",
    "        os.makedirs(final_dir)\n",
    "        \n",
    "    df_mu = pd.read_csv(f'../Data/preprocessed{namespace}/mu.csv', index_col=0)\n",
    "        \n",
    "    #create list of all minkowski file folders to evaluate\n",
    "    files = [directory + file for file in os.listdir(directory) if 'tomo' in file]\n",
    "    \n",
    "    #for folder in folders:\n",
    "    for i in trange(len(files)):\n",
    "        \n",
    "        #index has the form 'XXX_YYY' and is used to infer which of the resolutions is used\n",
    "        file_name = files[i]\n",
    "        index = file_name[-11:-4]\n",
    "        mu = df_mu.loc[index, 'mu']\n",
    "        df = pd.read_csv(file_name, index_col=0)\n",
    "        df['diameter'] = mu\n",
    "        \n",
    "        final_file = re.sub('preprocessed', 'final', file_name)\n",
    "        if os.path.isfile(final_file):\n",
    "            df_cut = pd.read_csv(final_file)\n",
    "        else:\n",
    "            df_cut = prepare_df(df, index)\n",
    "            df_cut.to_csv(final_file)\n",
    "        xyz = df[['x','y','z']].to_numpy()\n",
    "        xyz_cut = df_cut[['x','y','z']].to_numpy()\n",
    "    \n",
    "        interval, cns = cns_cut(xyz, xyz_cut, mu, upper_range = upper_range)\n",
    "\n",
    "        #open df, cut df, compute pcns, save pcns, save df, \n",
    "        sigma = sigma_from_cns(interval, cns, mu)\n",
    "        df_sigma.loc[index, 'sigma'] = sigma\n",
    "        df_cns = pd.DataFrame(data = {'interval':interval, 'cns':cns})\n",
    "        df_cns.to_csv(f'../Data/preprocessed{namespace}/cns_{index}.csv')\n",
    "        \n",
    "    df_sigma.to_csv(save_file)\n",
    "    \n",
    "def contacts_and_neighbours(directory, namespace = ''):\n",
    "\n",
    "    #compute mean sigmas\n",
    "    mean_sigmas = {res:compute_mean_sigma(sigma_file_path = f'../Data/preprocessed{namespace}/sigma.csv',resolution = res) for res in [20,30]}\n",
    "    #pick relevant sigma according to directory name\n",
    "    sigma = mean_sigmas[approximate_diameter(directory)]\n",
    "    df_mu = pd.read_csv(f'../Data/preprocessed{namespace}/mu.csv', index_col=0)\n",
    "    files = [directory + file for file in os.listdir(directory) if 'tomo' in file]\n",
    "    \n",
    "    for i in trange(len(files)):\n",
    "        #filename from preprocessed directory and other relevant files\n",
    "        file_name = files[i]\n",
    "        index = file_name[-11:-4]\n",
    "        poly_file = re.sub('preprocessed', 'raw', file_name)\n",
    "        poly_file = re.sub('.csv', '.poly', poly_file)\n",
    "        final_file = re.sub('preprocessed', f'final', file_name)\n",
    "        \n",
    "        #get presaved data to perform cns fit with constant mu and sigma\n",
    "        df_pcns = pd.read_csv(f'../Data/preprocessed{namespace}/cns_{index}.csv')\n",
    "        interval, cns = df_pcns.interval.values, df_pcns.cns.values\n",
    "        mu = df_mu.at[index, 'mu']\n",
    "\n",
    "        Z = Z_from_cns(interval, cns, mu, sigma)\n",
    "        df = pd.read_csv(file_name, index_col = 0)\n",
    "        df_cut = pd.read_csv(final_file, index_col = 0)\n",
    "        \n",
    "        xyz_cut = df_cut[['x','y','z']].to_numpy()\n",
    "        xyz = df[['x','y','z']].to_numpy()\n",
    "        df_cut[f'contact_number{namespace}'] = compute_local_contacts(xyz, xyz_cut, Z, interval, cns, namespace)\n",
    "        df_cut = compute_nearest_neighbours(df_cut, poly_file)\n",
    "        df_cut.to_csv(final_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85dc82ca-0b32-4e9a-a63a-ef193259066c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 265/265 [01:59<00:00,  2.23it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:36<00:00,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:35<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [01:55<00:00,  2.68it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [01:40<00:00,  2.63it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:30<00:00,  2.56it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:29<00:00,  2.60it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [01:49<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [03:40<00:00,  1.20it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [01:04<00:00,  1.20it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [01:04<00:00,  1.20it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [04:25<00:00,  1.16it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [02:25<00:00,  1.82it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:42<00:00,  1.81it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:42<00:00,  1.83it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [02:16<00:00,  2.25it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [01:57<00:00,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:34<00:00,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:35<00:00,  2.23it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [02:07<00:00,  2.42it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [03:44<00:00,  1.18it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [01:05<00:00,  1.19it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [01:06<00:00,  1.17it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [04:17<00:00,  1.19it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [02:46<00:00,  1.59it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:50<00:00,  1.55it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:50<00:00,  1.53it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [02:38<00:00,  1.94it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [02:14<00:00,  1.97it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:39<00:00,  1.95it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:40<00:00,  1.92it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [02:37<00:00,  1.95it/s]\n",
      "100%|█████████████████████████████████████████| 265/265 [04:03<00:00,  1.09it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [01:11<00:00,  1.10it/s]\n",
      "100%|███████████████████████████████████████████| 78/78 [01:11<00:00,  1.10it/s]\n",
      "100%|█████████████████████████████████████████| 308/308 [04:35<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "directories = ['../Data/preprocessed/VF_005_analysis/', '../Data/preprocessed/VF_006_analysis/',\n",
    "               '../Data/preprocessed/VF_007_analysis/', '../Data/preprocessed/VF_008_analysis/']\n",
    "\n",
    "for u_r, n_s in [(1.0, '_10'), (1.5, '_15'), (2.0, '')]:\n",
    "    for directory in directories:\n",
    "        compute_mu(directory, upper_range=u_r, namespace=n_s)\n",
    "    for directory in directories:\n",
    "        compute_sigmas(directory, upper_range=u_r, namespace=n_s)\n",
    "    for directory in directories:\n",
    "        contacts_and_neighbours(directory, namespace=n_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436cdf66-5b21-48e9-a24b-278589ae0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/final/'\n",
    "measurements = ['../Data/final/VF_005_analysis',\n",
    "                '../Data/final/VF_006_analysis',\n",
    "                '../Data/final/VF_007_analysis',\n",
    "                '../Data/final/VF_008_analysis']\n",
    "\n",
    "for measurement in measurements:\n",
    "    df = merge_measurements(measurement +'/')\n",
    "    df.to_csv(f'../Data/{measurement[14:20]}_og.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
